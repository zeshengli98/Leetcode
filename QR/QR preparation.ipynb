{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Quantitative Researcher Interview Preparation\n",
    "\n",
    "#### Abstract\n",
    "This is a document for preparing all kinds of probability, statistics, stochastic process, brain teasers for 2023 Quantitative Researcher position. I plan to aggregate and categorize the technical interview questions for myself to review and polish quantitative skills and mindset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Brain Teasers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.1 Coin weighing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### IMC sample test 08/25/2022\n",
    "You have 20 stacks of 30 coins each. The coins come into 2 types - U.S. coins, which weigh 25 grams each, and Canadian coins, which weigh 30 gram each.\n",
    "        \n",
    "Each Stack contains coins of only one type, and there is precisely one stack of Canadian coins. You have a digital scale which can tell you the exact weight of any combination of coins.\n",
    "        \n",
    "What is the minimum number of measurements you need to perform to guarantee that you find the stack of Canadian coins?\n",
    "\n",
    "##### Solution\n",
    "**One time.** I can place total 190 coins on the digital scale, 1 from the first stack, 2 from the second stack ... 20 from the last stack. If we assume all the coins are U.S. coins, we will get 25\\*190 = 4750grams on the scale, but this can't happen because there is exactly one stack of coins belongs to Canadian. Therefore, we can read the total number of grams and see the difference between the actual number and the ideal number (4750), so we can compute the difference and divide by 5 to get the number of Canadian coins in the stack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1 Random Variable\n",
    "Four independent random variable $X_i, 1 \\le i \\le 4$ are log-normally distributed, such that $lnX_i$ has mean 0.5 and variance 1.\n",
    "\n",
    "Which of the following is closest to the probability that the product of the $X_i$ is at least 50?\n",
    "\n",
    "##### Solution\n",
    "**33%**\n",
    "\n",
    "From definition, we know $lnX_i \\sim N(\\mu_i, \\sigma_i)$, so $\\sum LnX_i \\sim N(\\sum \\mu_i, \\sum \\sigma_i^2) $\n",
    "so the probability of$P(\\prod X_i > 50)$ can be combuted by:\n",
    "\n",
    "$$P(\\sum lnX_i > ln(50))$$\n",
    "\n",
    "$$P(\\frac{\\sum lnX_i - 4*0.5}{4*1} > \\frac{ln(50)-4*0.5}{4*1})$$\n",
    "\n",
    "\n",
    "$$P(\\phi > 0.478) \\approx 33\\%$$\n",
    "\n",
    "### 2.2 PRACTICE PROBLEMS\n",
    "Six friends bring Coke to a party, and each has 60% chance of bringing Coke. What is the probability that at least 2 people will bring Coke to the party? Round your answer to two decimal places.\n",
    "##### Solution\n",
    "**0.96**\n",
    "\n",
    "Let $A$ represents people with Coke, X represents the number of people bringing Coke so $P(A)=0.6$. \n",
    "\n",
    "$P(X>=2) = 1-P(X=0)-P(X=1)$\n",
    "\n",
    "$P(X=0) = 0.4^3C^0_6 = 0.0040$\n",
    "\n",
    "$P(X=1) = 0.6^10.4^5C^1_6 = 0.037$\n",
    "\n",
    "So, $P(X>=2) = 0.96$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Conditional Probability and Bayes' formula\n",
    "**Theorem1**: $$P(A|B) = \\frac{P(AB)}{P(B)}$$\n",
    "**Theorem2**: Multiplication Rule: $$P(E_1E_2...E_n) = P(E_1)P(E_2|E_1)P(E_3|E_1E_2)...P(E_n|E_1...E_{n-1})$$\n",
    "**Total probability**: $$P(E) = \\Sigma^n_{i=1}P(E|F_i)P(F_i)$$\n",
    "\n",
    "**Bayes' Formula**: $$P(A_i|B) = \\frac{P(A_iB)}{P(B)} = \\frac{P(B|A_i)P(A_i)}{\\Sigma^n_{i=1}P(B|A_i)P(A_i)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Aces\n",
    "52 cards are randomly distributed to 4 players, each player will get 13 cards. What is the probability that each of them will have an ace?\n",
    "\n",
    "***Solution*** $\\frac{52}{52}*\\frac{39}{51}*\\frac{26}{50}*\\frac{13}{49}$\n",
    "\n",
    "We can let $X_i$ represents the position of one card, so we have $X_1 - X_{13}, X_{14} - X_{26}, X_{27} - X_{39}, X_{40}-X{52}$ four piles of cards. Let's begin with any one of four aces, it has probability $\\frac{52}{52}$ of belonging to any one pile. The second ace can be any remaning 51 cards, and the probability of belong to the rest of 3 piles is $\\frac{39}{51}$. Then we have 50 cards left, among which 26 belong to the two piles. So the third ace is in one of the other 2 piles is $\\frac{26}{50}$. Similarly, the conditional probability of the last ace is in the last pile is $\\frac{13}{49}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Distributions\n",
    "#### Discrete distribution\n",
    "**Uniform** \n",
    "\n",
    "$$P(X)=\\frac1{b-a+1}, x=a,a+1,...,b$$     \n",
    "$$E[X] = \\frac{b+a}{2}, Var(X) = \\frac{(b-a+1)^2+1}{12}$$\n",
    "\n",
    "**Binomial**: the number of successes in a sequence of n experiments when each trail is independently a success with probability $p$\n",
    "$$P(X)=C^r_n p^x(1-p)^{n-x}, x=0,1,...,n$$     \n",
    "$$E[X] = np, Var(X) = np(1-p)$$\n",
    "\n",
    "\n",
    "**Possion**: the number of events occurring in a fixed period of time with the expected number of occurrences $\\lambda t$ when events occur with a known average rate $\\lambda$ and are independent of the time since last event.\n",
    "$$P(X)=\\frac{e^{\\lambda t}(\\lambda t)^x}{x!}, x=1,2,...$$     \n",
    "$$E[X] = \\lambda t, Var(X) = \\lambda t$$\n",
    "\n",
    "#### Continous distribution\n",
    "**Uniform** \n",
    "\n",
    "$$P(X)=\\frac1{b-a}, a \\le x \\le b$$     \n",
    "$$E[X] = \\frac{b+a}{2}, Var(X) = \\frac{(b-a)^2}{12}$$\n",
    "\n",
    "**Normal** \n",
    "\n",
    "$$P(X)=\\frac1{\\sqrt{2\\pi}\\sigma}e^{\\frac{-(x-\\mu)^2}{2\\sigma^2}}$$     \n",
    "$$E[X] = \\mu, Var(X) = \\sigma^2$$\n",
    "\n",
    "**Exponential**: the arrival time of an event if it has a constant arrival rate $\\lambda$\n",
    "\n",
    "$$P(X)=\\lambda e^{-\\lambda x} , x \\ge 0$$     \n",
    "$$E[X] = 1/\\lambda, Var(X) = 1/\\lambda^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Permutation and combination\n",
    "### 3.1 IMC Q15\n",
    "You are going to go on a five days trip and there are 8 locations to visit over the course of trip. On any given day, you could visit as many of the locations as you want in any order that you desire.\n",
    "\n",
    "How many different schedules can you make for your trip given that you must visit each location exactly once?\n",
    "\n",
    "##### Solution\n",
    "$C^4_{12} * 8!$\n",
    "\n",
    "We can look seperately for this kind of problems.\n",
    "\n",
    "In how many ways can some or all of the 8 distinct coins be put into 5 pockets in order(all coins should be put into one pocket)?\n",
    "\n",
    "Let's simplify the problem first. \n",
    "1) Assume we don't consider the order we put coins into pocket. So each coin has 5 pockets to go, and second has 5 pockets to go as well... In total we have $5^8$ combinations.\n",
    "\n",
    "2) Therefore, if we add the order restriction here, we should consider permutations and combinations separately and apply the multiplication rule. Let's consider how many combinations of locations we have in five days. Suppose we have four blocks dividing the locations into five days, then we can calculate the number of combinations of blockers and locations: we have $C^4_{12}$ situations. We can then permute the order of all locations, so the final case will be $8! * C^4_{12}$ \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2. Inclusion-Exclsion Principle\n",
    "$$P(E_1 \\cup E_2) = P(E_1)+P(E_2)-P(E_1E_2)$$\n",
    "\n",
    "And generally:\n",
    "$$P(E_1 \\cup E_2 \\cup ... \\cup E_N) = \\Sigma^n_{N=1}P(E_i) - \\Sigma_{i_1 \\le i_2}P(E_{i_1}E_{i_2}) + ...(-1)^{r+1}\\Sigma_{i_1 \\le i_2 \\le...i_r}P(E_{i_1}E_{i_2}...E_{i_r})+...(-1)^{N+1}P(E_1E_2...E_N)$$\n",
    "\n",
    "$\\Sigma_{i_1 \\le i_2 \\le...i_r}P(E_{i_1}E_{i_2}...E_{i_r})$ has $C^r_N terms$\n",
    "### A pratical Guide P69-Application letters\n",
    "You are sending job application to A,B,C,D,E. And you randomly send 5 personalized cover letter to the campanies. What is the probability that all 5 cover letters are mailed to the wrong firms?\n",
    "\n",
    "***Solution*** $\\frac{11}{30}$\n",
    "\n",
    "Let's denote by $E_i, i =1,2,3,4,5$ the event that i-th letter has mailed to correct company. So $P(\\bigcup_{i=1}^5 E_i) $represents at least one letter mailed to correct one. So the result answer will be $1-P(\\bigcup_{i=1}^5 E_i)$\n",
    "\n",
    "Based on the include-exclude principle:\n",
    "$$P(\\bigcup_{i=1}^5 E_i)=\\Sigma_{i=1}^5P(E_i)-\\Sigma_{i_1<i_2}^5P(E_{i_1}E_{i_2}) +...+ (-1)^6P(E_1E_2...E_5) $$\n",
    "\n",
    "The first term is obviously equal to 1. $\\Sigma_{i_1<i_2}^5P(E_{i_1}E_{i_2})$ is the event that both letter $i_1$ and $i_2$ have mailed to the correct one. So $\\Sigma_{i_1<i_2}^5P(E_{i_1}E_{i_2}) = C^2_5 * \\frac15 * \\frac14 = \\frac1{2!}$\n",
    "\n",
    "So, at last, $$P(\\bigcup_{i=1}^5 E_i) = 1-\\frac1{2!}+\\frac1{3!}-\\frac1{4!}+\\frac1{5!}=\\frac{19}{30}$$, so the answer is $1-\\frac{19}{30} = \\frac{11}{30}$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Markov Chain\n",
    "### 4.1 Expected Value\n",
    "**Theorem1**: If an event has a probability of p to occur in a trial, then the expected number of trials to obtain the first occurrence of this event in a sequence of trials is $\\frac1p$\n",
    "\n",
    "**Q1** What is the expected number of rolls of a fair die until all 6 numbers turn up?\n",
    "**14.7**\n",
    "\n",
    "The first number turns up on the first roll with a prob of 1. So the expected number of getting first number is 1. After that, a different number turns up with a prob of $\\frac56$. By the theorem above, the expected value of getting a different number is $\\frac65$, so we can proceed with similar reasoning and get the answer:\n",
    "\n",
    "$$1+\\frac65+\\frac64+\\frac63+\\frac62+\\frac61=14.7$$\n",
    "\n",
    "**Theorem2**: Linearity of Expectation:\n",
    "$$E(X+Y) = E(X)+E(Y)$$\n",
    "**Theorem3 **: If X is a r.v. taking only non-negative integer values:\n",
    "$$E(X) = \\Sigma_{i=1}^\\infty P(X\\ge i)$$\n",
    "\n",
    "**Q2** What is the expected number of real numbers, chosen uniformly at random from the interval [0,1], one must select until their sum exceeds 1?\n",
    "**e**\n",
    "\n",
    "### 4.2 Markov Chain - small number of states - simultaneous equations\n",
    "**Important Logic:** The expected number of steps in given state into $E[n|x_t = x] = 1 + \\Sigma_y E[n|x_{t+1}=y]p(x_{t+1}=y|x_{t}=x)$ - the expected number of steps starting in a given (non absorbing) state is the 1 + expected number steps from every possible subsequent state, weighted by the probability of ending up in that state.\n",
    "\n",
    "**Q1** I repeatedly flip a fair coin. What is the expected number of flips I need to make before I get two heads in a row?\n",
    "\n",
    "***Solution*** \n",
    "\n",
    "So now we have 3 states:\n",
    " - 0: No heads so far. This is the state we start in\n",
    " - 1: 1 head.\n",
    " - 2: 2 heads, the absorbing state.\n",
    " \n",
    "Let $E[i]$ be the expected number of steps the process takes to reach the absorbing state 2 from i, and clearly $E[2]=0$\n",
    "\n",
    "$$E[1] = 1 + \\frac12E[0]+\\frac12E[2] = 1+\\frac12E[0]$$\n",
    "$$E[0] = 1 + \\frac12E[1]+\\frac12E[0]$$\n",
    "\n",
    "so, $E[0]=6$\n",
    "\n",
    "**Q2**\n",
    "A process moves on the integers 1, 2, 3, 4, and 5. It starts at 1 and, on each successive step, moves to an integer greater than its present position, moving with equal probability to each of the remaining larger integers, until it reaches 5. Find the expected number of steps it takes to reach the integer five.\n",
    "\n",
    "***Solution*** \n",
    "Using the same method above to recursion problems is easy. Let $E[i]$ be the expected number of steps the process takes to reach the absorbing state 5 from i, and clearly $E[5]=0, E[4]=1$, then we can compute $E[3] = 1+ \\frac12E[4]+\\frac12E[5] = \\frac32$.\n",
    "\n",
    "Similarly, when the process is at 2, there is a 1/3 probability to reach either 3, 4 and 5. Thus: \n",
    "$$E[2] = 1+ \\frac13E[3]+\\frac13E[4]+\\frac13E[5] = \\frac{11}{6}$$.\n",
    "\n",
    "Finally, we have 1/4 probability to reach 2,3,4 and 5 respectively. Therefore:\n",
    "$$E[1] = 1+ \\frac14E[2]+\\frac14E[3]+\\frac14E[4]+\\frac14E[5]  = \\frac{25}{12}$$.\n",
    "\n",
    "### 4.3 Gambler's ruin problem\n",
    "Player M has \\\\$1, and player N has \\\\$2. Each game gives the winner \\\\$1 from the other. As a better player, M wins 2/3 of the games. They play until one of them is bankrupt. What's the prob that M wins?\n",
    "\n",
    "***Solution*** 4/7\n",
    "This problem with boundary can be solved with pretty similar technique above. We define $P_i$ as player M winning probability at \\\\$i. So clearly, $P_0 = 0, P_3 = 1$\n",
    "\n",
    "Then we can apply the absorption probability equations:\n",
    "$$P_1 = \\frac13P_0 + \\frac23P_2$$\n",
    "$$P_2 = \\frac13P_1 + \\frac23P_3$$\n",
    "\n",
    "Finally, we can solve the equation and get $P_1 = \\frac47$\n",
    "\n",
    "### 4.4 Infinity Boundary Problem\n",
    "#### 4.4.1 The Drunkard’s Walk\n",
    "\n",
    "There once was a drunk man who wandered far too close to a cliff. From where he stands, one step forward would send the drunk man over the edge. He takes random steps, either towards or away from the cliff. At any step, his probability of taking a step away is 2/3 and a step towards the cliff is 1/3. What is his chance of escaping the cliff?\n",
    "\n",
    "***Solution*** 1/2\n",
    "\n",
    "Let's consider a more general situation. Define the probability of falling off the cliff from 1 is $P_1$, This is of interest since it is always the prerequisite step for falling off the cliff.\n",
    " - If the prob of stepping immediately left to 0 is 1-p\n",
    " - The prob of leaving the cliff and move right to 2 is p\n",
    "We can obtain the equation:\n",
    "$$P_1 = (1-p)P_0 + pP_2$$\n",
    "\n",
    "A important question: what is $P_2$?\n",
    "P2 is the probability of falling off the cliff on a path originating from 2 steps away. In order to fall off the cliff you have to move from 2 → 1 and from 1 → 0. The step in the walk is independent, so the move from 2 → 1 exactly behaves the same way as 1 → 0, so we can use 2-step $P_1$ represent the $P_2$. We can restructure the equation:\n",
    "\n",
    "$$P_1 = (1-p)P_0 + pP_1^2$$\n",
    "$$P_1 = 1, \\frac{1-p}{p}$$\n",
    "\n",
    "We should look at the solution as a piecewise function. Those P1 with p < 1/2, we can see the drunkard 100% fall into the cliff, if p >= 1/2, we can calculate the probability of falling off by $\\frac{1-p}{p}$. Back to our origin problem, the probability of falling is 1/2, so the escaping prob is also 50%.\n",
    "\n",
    "#### 4.4.2 Gambler's ruin problem with single boundary\n",
    "You are playing a game. Every round, you flip a coin. If you get tails, you lose \\\\$1. If you get heads you win \\\\$2. At the start of the game, you have N dollars, and you must stop playing the game if you run out of money. What is the probability you never go bankrupt, if you play as long as you are able to?\n",
    "\n",
    "***Solution*** $P = 1-(\\frac{\\sqrt{5}}{2}-\\frac12)^N$\n",
    "\n",
    "Let $P_i$ represents the bankrupt probablity at \\\\$i, so clearly $P_0 = 1$, and $P_1$ is the state of interest because every bankrupt happen must go through this state, so it's the prerequisite of the bankrupt. \n",
    " \n",
    "For state 1, we can obtain:\n",
    "$$P_1 = \\frac12P_0 + \\frac12P_3$$\n",
    "\n",
    "The similar reasoning as above technique, $P_3$ is the probability of bankrupt when player has \\\\$3, so we can consider the $P_3$ as 3-step $P_1$ because those states are independent. So we can get the new equation:\n",
    "\n",
    "$$P_1 = \\frac12 + \\frac12P_1^3$$\n",
    "$P_1 = 1, \\frac{\\sqrt{5}}{2}-\\frac12, -\\frac{\\sqrt{5}}{2}-\\frac12$, we need to have the condition that $0<P_1<1$, so we can drop the negative prob, and 1.\n",
    "\n",
    "So the probability of not being bankrupt is $P_N = 1-(\\frac{\\sqrt{5}}{2}-\\frac12)^N$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}